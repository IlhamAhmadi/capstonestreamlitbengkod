# -*- coding: utf-8 -*-
"""BengkodTugasAkhir

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1selfCwN776lbkjjxsUhOBOXGi-RNBzK-

## Exploratory Data Analysis (EDA)

- import dan load data
"""

# Import library dasar
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns

pd.show_versions(as_json=False)

# Load dataset
df = pd.read_csv('/content/ObesityDataSet.csv')

"""- tampilkan dataset"""

# Lihat 5 data teratas
df.head()

"""- Informasi data"""

df.info()

"""- Dimensi data"""

df.shape

"""- Statistik deskriptif"""

df.describe()

"""- Visualisasi distribusi data"""

plt.figure(figsize=(15, 15))
for i, col in enumerate(df.columns, 1):
    plt.subplot(5, 4, i)
    sns.countplot(data=df, x=col)
    plt.title(f'{col} distribution')
    plt.tight_layout()

plt.show()

"""- cek missing value"""

df.isnull().sum()

"""- cek data Duplikat"""

df.duplicated().sum()

"""- Nilai Unik (persebaran value dalam fitur)"""

for col in df.columns:
  print(f'{col}')
  print(f'Jumlah nilai yang unik: {df[col].nunique()}')
  print(f'Nilai yang paling sering muncul (modus): {df[col].mode().values[0]}')
  print(f'{df[col].unique()}\n')

"""- Mengganti nilai '?' dengan NaN"""

df.replace('?', np.nan, inplace=True)

# Cek kembali missing values setelah mengganti '?'
print("Jumlah missing values setelah mengganti '?':")
print(df.isnull().sum())

"""- menampilkan value dalam fitur NObeyesdad"""

df['NObeyesdad'].value_counts().plot(kind='bar',figsize=(10,6),color=['green'])
plt.title("Count of the Obesitas")
plt.xticks(rotation=0)

"""- menampilkan outlier"""

rows, cols = 5, 4
fig, axes = plt.subplots(rows, cols, figsize=(12, 8))
axes = axes.flatten()
for i, col in enumerate(df.columns):
    sns.boxplot(x=df[col], ax=axes[i])
    axes[i].set_title(f'Boxplot {col}')
for j in range(len(df.columns), len(axes)):
    fig.delaxes(axes[j])
plt.tight_layout()
plt.show()

"""KESIMPULAN KATA KATA HARI INI

Beberapa value dalam fiturnya terdapat nilai '?' dan harus diubah menjadi 'nan' sehingga bisa dihandling missing value. pada bagian deteksi outlier terdapat beberapa fitur yang harus di handling dan tidak boleh di handling

## PREPROCESSING DATA

* Cek jumlah missing values
"""

df.isnull().sum()

"""- mengubah tipe data yang terdeteksi salah dari object ke float"""

# Daftar kolom yang ingin dikonversi
numeric_columns = ['Age', 'Height', 'Weight', 'FCVC', 'NCP', 'CH2O', 'FAF', 'TUE']

# Konversi ke float64
for col in numeric_columns:
    df[col] = pd.to_numeric(df[col], errors='coerce')  # ubah ke float64, error jadi NaN jika ada

# Verifikasi tipe data
print(df[numeric_columns].dtypes)

df.info()

"""- memisahkan numerik dan kategorikal"""

num_cols = df.select_dtypes(include=['int64', 'float64']).columns
cat_cols = df.select_dtypes(include=['object' ]).columns

print (num_cols)
print (cat_cols)

"""- mengatasi missing value dari data numerik menggunakan median"""

for col in num_cols:
  median_value = df[col].median()
  df[col].fillna(median_value, inplace=True)

"""* mengatasi missing value dari data kategorikal menggunakan modus"""

for col in cat_cols:
  mode_value = df[col].mode() [0]
  df[col]. fillna(mode_value, inplace=True)

"""- cek kembali missing value"""

df.isnull().sum()

"""* Memeriksa keberadaan duplikat"""

df.duplicated().sum()
df[df.duplicated(keep=False)]

"""- handling duplikat dengan drop"""

df.drop_duplicates(inplace=True)
df.duplicated().sum()
df [df.duplicated() ]

"""- encoding (mengubah nilai kategori menjadi numerik)"""

from sklearn.preprocessing import LabelEncoder

for col in cat_cols:
  df[col] = LabelEncoder(). fit_transform(df[col])

"""- menampilkan outlier dengan boxplot"""

rows, cols = 5, 4
fig, axes = plt.subplots(rows, cols, figsize=(12, 8))
axes = axes.flatten()
for i, col in enumerate(df.columns):
    sns.boxplot(x=df[col], ax=axes[i])
    axes[i].set_title(f'Boxplot {col}')
for j in range(len(df.columns), len(axes)):
    fig.delaxes(axes[j])
plt.tight_layout()
plt.show()

"""- menampilkan value dalam fitur NObeyesdad"""

df['NObeyesdad'].value_counts().plot(kind='bar', figsize=(10,6), color=['green' ])
plt.title("Count of the Heart Disease")
plt.xticks(rotation=0);

"""- handling imbalanced menggunakan oversampling dari SMOTE"""

from imblearn.over_sampling import SMOTE

y = df ['NObeyesdad' ]
X = df. drop(columns=['NObeyesdad' ])
smote = SMOTE()
X_resampled, y_resampled = smote.fit_resample(X, y)
print("Sebelum SMOTE:", y.value_counts())
print("Setelah SMOTE:", pd. Series(y_resampled).value_counts())

"""- visualisasi setelah di oversampling"""

y_resampled.value_counts().plot(kind='bar', figsize=(10,6), color=['green' ])
plt.title("Count of the Heart Disease")
plt.xticks(rotation=0);

"""- menggabungkan kelas target yang sudah di handling ke dalam data frame"""

df_resampled = pd.concat([pd.DataFrame(X_resampled, columns=X.columns),
pd. Series(y_resampled, name='num') ], axis=1)

df = df_resampled

"""- splitting data"""

from sklearn.preprocessing import StandardScaler
from sklearn.model_selection import train_test_split

# Use the resampled data after SMOTE
X = df_resampled.drop(columns=['num']) # Drop the 'num' column which was the target after SMOTE
y = df_resampled['num']              # Use the 'num' column as the target label

# Split the data into training and testing sets
# Using a 90:10 split as indicated in the comments
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=42, stratify=y)


sc = StandardScaler()
X_train = sc.fit_transform(X_train)
X_test = sc.transform(X_test)

"""KESIMPULAN KATA KATA HARI INI

Pada proses ini handling outlier tidak dilakukan karena setelah di encoder dan dideteksi melalui IQR data terdeteksi outlier tapi sebenarnya itu bukan outlier melainkan memang data asli.

untuk feature, semua feature digunakan karena dataset obesitas termasuk ke dalam golongan kesehatan jadi mungkin semua feature digunakan karna mempengaruhi fitur lainnya

Saya menggunakan splitting 90/10 untuk 90 adalah data training dan 10 data test. kemudian saya menggunakan standarisasi StandardScaler. saya menggunakan over sampling dari SMOTE untuk balancing fitur target

## PEMODELAN DAN EVALUASI

- import library untuk pemodelan
"""

from sklearn.model_selection import train_test_split
from sklearn.metrics import classification_report, confusion_matrix, accuracy_score
from sklearn.naive_bayes import GaussianNB
from sklearn.tree import DecisionTreeClassifier
from sklearn.neighbors import KNeighborsClassifier

# Naive Bayes
nb = GaussianNB()
nb.fit(X_train, y_train)
y_pred_nb = nb.predict(X_test)
print("=== Naive Bayes ===")
print(classification_report(y_test, y_pred_nb))
print(confusion_matrix(y_test, y_pred_nb))
print("Akurasi:", accuracy_score(y_test, y_pred_nb))

# Decision Tree
dt = DecisionTreeClassifier()
dt.fit(X_train, y_train)
y_pred_dt = dt.predict(X_test)
print("\n=== Decision Tree ===")
print(classification_report(y_test, y_pred_dt))
print(confusion_matrix(y_test, y_pred_dt))
print("Akurasi:", accuracy_score(y_test, y_pred_dt))

# K-Nearest Neighbors
from sklearn.neighbors import KNeighborsClassifier

knn = KNeighborsClassifier()
knn.fit(X_train, y_train)
y_pred_knn = knn.predict(X_test)
print("\n=== K-Nearest Neighbors ===")
print(classification_report(y_test, y_pred_knn))
print(confusion_matrix(y_test, y_pred_knn))
print("Akurasi:", accuracy_score(y_test, y_pred_knn))

"""- perbandingan akurasi 3 model menggunakan chart"""

# Akurasi Chart
akurasis_before  = {
    'Naive Bayes': accuracy_score(y_test, y_pred_nb),
    'Decision Tree': accuracy_score(y_test, y_pred_dt),
    'KNN': accuracy_score(y_test, y_pred_knn)
}

plt.figure(figsize=(8, 5))
sns.barplot(x=list(akurasis_before .keys()), y=list(akurasis_before .values()))
plt.title('Perbandingan Akurasi Model')
plt.ylabel('Akurasi')
plt.ylim(0, 1)
for i, acc in enumerate(akurasis_before .values()):
    plt.text(i, acc + 0.02, f"{acc:.2f}", ha='center')
plt.show()

import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.metrics import ConfusionMatrixDisplay

# Confusion Matrix
models = {
    "Naive Bayes": y_pred_nb,
    "Decision Tree": y_pred_dt,
    "KNN": y_pred_knn
}

fig, axes = plt.subplots(1, 3, figsize=(18, 5))
for ax, (name, y_pred) in zip(axes, models.items()):
    cm = confusion_matrix(y_test, y_pred)
    sns.heatmap(cm, annot=True, fmt='d', cmap='Reds', ax=ax)
    ax.set_title(f'Confusion Matrix - {name}')
    ax.set_xlabel('Predicted')
    ax.set_ylabel('Actual')

plt.tight_layout()
plt.show()

"""KESIMPULAN KATA KATA HARI INI

Dari dataset yang digunakan dan setelah di processing maka model yang cocok berdasarkan akurasi adalah decision tree lalu disusul dengan KNN dan Naive Bayes

Untuk evaluasi juga yang paling baik adalah Decision Tree berdasakan klasifikasi report

## HYPERPARAMETER TUNING

- import library
"""

from sklearn.model_selection import GridSearchCV

"""- hyperparameter tuning untuk Naive Bayes"""

import numpy as np
param_grid_nb = {
    'var_smoothing': np.logspace(0, -9, num=100)
}
nb_model = GaussianNB()
grid_search_nb = GridSearchCV(estimator=nb_model, param_grid=param_grid_nb, cv=5, scoring='accuracy')
grid_search_nb.fit(X_train, y_train.values.ravel()) # Menggunakan .values.ravel() karena y_train adalah DataFrame
print("Best hyperparameters for Naive Bayes:", grid_search_nb.best_params_)
print("Best cross-validation accuracy for Naive Bayes:", grid_search_nb.best_score_)
best_nb_model = grid_search_nb.best_estimator_
y_pred_nb_tuned = best_nb_model.predict(X_test)
print(classification_report(y_test, y_pred_nb_tuned))
print(confusion_matrix(y_test, y_pred_nb_tuned))
print("Akurasi:", accuracy_score(y_test, y_pred_nb_tuned))

"""- hyperparameter tuning untuk Decision Tree"""

param_grid_dt = {
    'criterion': ['gini', 'entropy'],
    'max_depth': [None, 5, 10, 15, 20],
    'min_samples_split': [2, 5, 10],
    'min_samples_leaf': [1, 2, 4]
}
dt_model = DecisionTreeClassifier(random_state=42)
grid_search_dt = GridSearchCV(estimator=dt_model, param_grid=param_grid_dt, cv=5, scoring='accuracy')
grid_search_dt.fit(X_train, y_train.values.ravel())
print("\nBest hyperparameters for Decision Tree:", grid_search_dt.best_params_)
print("Best cross-validation accuracy for Decision Tree:", grid_search_dt.best_score_)
best_dt_model = grid_search_dt.best_estimator_
y_pred_dt_tuned = best_dt_model.predict(X_test)
print(classification_report(y_test, y_pred_dt_tuned))
print(confusion_matrix(y_test, y_pred_dt_tuned))
print("Akurasi:", accuracy_score(y_test, y_pred_dt_tuned))

"""- hyperparameter tuning untuk KNN"""

import matplotlib.pyplot as plt
param_grid_knn = {
    'n_neighbors': list(range(1, 31)),
    'weights': ['uniform', 'distance'],
    'metric': ['euclidean', 'manhattan', 'minkowski']
}
knn_model = KNeighborsClassifier()
grid_search_knn = GridSearchCV(estimator=knn_model, param_grid=param_grid_knn, cv=5, scoring='accuracy')
grid_search_knn.fit(X_train, y_train.values.ravel())
print("\nBest hyperparameters for KNN:", grid_search_knn.best_params_)
print("Best cross-validation accuracy for KNN:", grid_search_knn.best_score_)
best_knn_model = grid_search_knn.best_estimator_
y_pred_knn_tuned = best_knn_model.predict(X_test)
print(classification_report(y_test, y_pred_knn_tuned))
print(confusion_matrix(y_test, y_pred_knn_tuned))
print("Akurasi:", accuracy_score(y_test, y_pred_knn_tuned))

"""- Evaluasi model"""

# === Evaluasi Model ===
def evaluasi_model(nama_model, y_true, y_pred):
    print(f"\n=== {nama_model} ===")
    print("Akurasi:", accuracy_score(y_true, y_pred))
    print("Confusion Matrix:\n", confusion_matrix(y_true, y_pred))
    print("Classification Report:\n", classification_report(y_true, y_pred))

evaluasi_model("Naive Bayes (Tuned)", y_test, y_pred_nb_tuned)
evaluasi_model("Decision Tree (Tuned)", y_test, y_pred_dt_tuned)
evaluasi_model("KNN (Tuned)", y_test, y_pred_knn_tuned)

"""- perbandingan setelah di hyperparameter"""

models = {
    "Naive Bayes": y_pred_nb,
    "Decision Tree": y_pred_dt,
    "KNN": y_pred_knn
}

fig, axes = plt.subplots(1, 3, figsize=(18, 5))
for ax, (model_name, predictions) in zip(axes, models.items()):
    cm = confusion_matrix(y_test, predictions)
    sns.heatmap(cm, annot=True, fmt='d', cmap='Reds', ax=ax)
    ax.set_title(f'Confusion Matrix - {model_name}')
    ax.set_xlabel('Prediksi')
    ax.set_ylabel('Aktual')

plt.tight_layout()
plt.show()

"""- Visualisasi Perbandingan Akurasi"""

akurasi_after  = {
    'Naive Bayes (Tuned)': accuracy_score(y_test, y_pred_nb_tuned),
    'Decision Tree (Tuned)': accuracy_score(y_test, y_pred_dt_tuned),
    'KNN (Tuned)': accuracy_score(y_test, y_pred_knn_tuned)
}

plt.figure(figsize=(8, 5))
sns.barplot(x=list(akurasi_after .keys()), y=list(akurasi_after .values()))
plt.ylim(0, 1)
for i, acc in enumerate(akurasi_after .values()):
    plt.text(i, acc + 0.02, f"{acc:.2f}", ha='center')
plt.title('Perbandingan Akurasi Model')
plt.ylabel('Akurasi')
plt.show()

"""- Visualisasi Gabungan"""

# Pastikan semua didefinisikan sebelum digunakan
akurasis_after  = {
    'Naive Bayes (Tuned)': accuracy_score(y_test, y_pred_nb_tuned),
    'Decision Tree (Tuned)': accuracy_score(y_test, y_pred_dt_tuned),
    'KNN (Tuned)': accuracy_score(y_test, y_pred_knn_tuned)
}

labels = list(akurasis_before.keys())
before_scores = list(akurasis_before.values())

# Gunakan akurasi_after yang baru saja didefinisikan
after_scores = list(akurasis_after.values())

x = range(len(labels))
width = 0.35

plt.figure(figsize=(10, 6))
plt.bar(x, before_scores, width=width, label='Sebelum Tuning', color='skyblue')
plt.bar([i + width for i in x], after_scores, width=width, label='Sesudah Tuning', color='orange')
plt.xticks([i + width / 2 for i in x], labels)
plt.ylim(0, 1)
plt.ylabel('Akurasi')
plt.title('Perbandingan Akurasi Sebelum dan Sesudah Tuning')
plt.legend()

# Tambahkan label angka
for i in x:
    plt.text(i, before_scores[i] + 0.02, f"{before_scores[i]:.2f}", ha='center')
    plt.text(i + width, after_scores[i] + 0.02, f"{after_scores[i]:.2f}", ha='center')

plt.show()

"""KESIMPULAN KATA KATA HARI INI

setelah saya hyperparameter tuning terdapat hasil yang berbeda-beda tiap modelnya, untuk model Naive Bayes mengalami peningkatan sebanyak 0,01, kemudian Decision Tree tidak mengalami peningkatan atau penurunan, dan KNN mengalami peningkatan sebanyak 0,10.

KESIMPULAN SECARA KESELURUHAN

Dalam proyek ini, dilakukan pemrosesan data pada dataset obesitas dengan pendekatan yang mempertimbangkan karakteristik khusus dari data kesehatan. Tahap awal mencakup penanganan missing value dengan mengganti nilai '?' menjadi NaN, sehingga memungkinkan penanganan yang tepat terhadap data yang hilang. Untuk deteksi outlier, digunakan metode IQR, namun tidak semua data yang terdeteksi sebagai outlier dihapus atau diubah, karena sebagian merupakan data asli yang valid dan mencerminkan kondisi nyata pasien.

Seluruh fitur dalam dataset dipertahankan dan digunakan dalam pelatihan model, mengingat pentingnya setiap fitur dalam konteks kesehatan, di mana satu variabel dapat memengaruhi variabel lainnya. Data dibagi dengan rasio 90% untuk pelatihan dan 10% untuk pengujian. Selain itu, dilakukan standarisasi menggunakan StandardScaler serta oversampling menggunakan SMOTE untuk mengatasi ketidakseimbangan pada kelas target.

Dalam pemodelan, algoritma Decision Tree menunjukkan performa terbaik baik dari segi akurasi maupun evaluasi klasifikasi (classification report), disusul oleh K-Nearest Neighbors (KNN) dan Naive Bayes. Setelah dilakukan hyperparameter tuning, model KNN menunjukkan peningkatan performa paling signifikan sebesar 0,10, sementara Naive Bayes mengalami peningkatan kecil sebesar 0,01, dan Decision Tree tetap stabil tanpa perubahan performa.

Secara keseluruhan, pendekatan preprocessing yang selektif serta pemilihan model yang tepat berhasil menghasilkan sistem klasifikasi obesitas yang cukup andal dan sesuai untuk digunakan dalam konteks data kesehatan.
"""